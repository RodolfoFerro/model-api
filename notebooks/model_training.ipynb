{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP+kSFcSqNIvxaeyxpBZgze",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/model-api/blob/main/notebooks/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aprendizaje profundo - Empaquetado de modelos **\n",
        "\n",
        "> **Descripci贸n:** Cuaderno de contenidos del m贸dulo de aprendizaje profundo para el Dimplomado en Ciencia de Datos de la ENES UNAM Le贸n, 2024. <br>\n",
        "> **Autor:** [Rodolfo Ferro](https://github.com/RodolfoFerro) <br>\n",
        "> **Contacto:** [ferro@cimat.mx](mailto:ferro@cimat.mx)"
      ],
      "metadata": {
        "id": "RC_naIiJRAey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importar paqueter铆as**"
      ],
      "metadata": {
        "id": "E-Y3wQ31Rrlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "AifkKlBNOC1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "Whfnb59QUC5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cargar y visualizar los datos de Iris**\n",
        "\n",
        "\n",
        "En esta secci贸n, importamos las bibliotecas necesarias y cargamos el popular conjunto de datos de Iris. Luego, mostramos los primeros cinco ejemplos de datos y sus etiquetas correspondientes.\n",
        "\n",
        "> - **Wikipedia:** [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set)"
      ],
      "metadata": {
        "id": "hTzuGIBWRvEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el conjunto de datos de Iris\n",
        "iris_data = load_iris()\n",
        "\n",
        "# Mostramos ejemplos de los datos y etiquetas\n",
        "print('Example data: ')\n",
        "print(iris_data.data[:5])\n",
        "\n",
        "print('Example labels: ')\n",
        "print(iris_data.target[:5])"
      ],
      "metadata": {
        "id": "5Ov13fv5OH8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparar los datos para el entrenamiento**\n",
        "\n",
        "Aqu铆 se preparan los datos para el entrenamiento. Separamos las caracter铆sticas (X) de las etiquetas (y) y dividimos el conjunto de datos en dos subconjuntos: uno para entrenamiento y otro para prueba.\n",
        "\n"
      ],
      "metadata": {
        "id": "1V9xCdkqSC69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = iris_data.data\n",
        "y = iris_data.target.reshape(-1, 1)  # Convertimos los datos a una sola columna\n",
        "\n",
        "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.20)"
      ],
      "metadata": {
        "id": "1Sun0UMAOXn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Construcci贸n del modelo**\n",
        "\n",
        "En esta secci贸n, construimos un modelo de red neuronal secuencial utilizando Keras. La red tiene una capa de entrada de tama帽o 4, una capa oculta con 10 neuronas y una capa de salida con 3 neuronas, correspondientes a las clases de las especies de Iris.\n",
        "\n"
      ],
      "metadata": {
        "id": "xvVDLIHsSMrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construimos el modelo secuencial de Keras\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(4,)),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Mostramos un resumen de la arquitectura del modelo\n",
        "print('Neural Network Model Summary: ')\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "92KgCBjSOqD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Compilar el modelo**\n",
        "\n",
        "Aqu铆 compilamos el modelo, especificando el optimizador `Adam` y la funci贸n de p茅rdida `SparseCategoricalCrossentropy`, que es adecuada para problemas de clasificaci贸n con etiquetas enteras.\n"
      ],
      "metadata": {
        "id": "XuGPkUcETDOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuramos el optimizador y la funci贸n de p茅rdida\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Compilamos el modelo con el optimizador y la funci贸n de p茅rdida\n",
        "model.compile(optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eEIZXLCQO1xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Entrenar el modelo**\n",
        "\n",
        "En esta celda, entrenamos el modelo utilizando los datos de entrenamiento. El entrenamiento se realiza en 200 茅pocas con un tama帽o de lote de 5."
      ],
      "metadata": {
        "id": "x7VEd5grTMTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con los datos de entrenamiento\n",
        "history = model.fit(train_x, train_y, batch_size=5, epochs=200)"
      ],
      "metadata": {
        "id": "hX03i5VbPLMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualizar la historia del entrenamiento**\n",
        "\n",
        "Esta secci贸n crea un gr谩fico interactivo utilizando Plotly para visualizar la evoluci贸n de la precisi贸n y la p茅rdida del modelo durante el entrenamiento."
      ],
      "metadata": {
        "id": "c9d_N3KoTTBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_acc = history.history['accuracy']\n",
        "hist_loss = history.history['loss']\n",
        "eje_x = np.arange(len(hist_acc))\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=eje_x,\n",
        "                         y=hist_acc,\n",
        "                         mode='lines',\n",
        "                         name='Accuracy'))\n",
        "fig.add_trace(go.Scatter(x=eje_x,\n",
        "                         y=hist_loss,\n",
        "                         mode='lines',\n",
        "                         name='Loss'))\n",
        "fig.update_layout(title='Historia de entrenamiento',\n",
        "                   xaxis_title='pocas',\n",
        "                   yaxis_title='Loss/Accuracy')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "NsXke2SzPa-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluar el modelo en datos no vistos**\n",
        "\n",
        "Aqu铆 evaluamos el modelo utilizando los datos de prueba para ver c贸mo se desempe帽a en datos no vistos. Mostramos la p茅rdida y la precisi贸n en el conjunto de prueba."
      ],
      "metadata": {
        "id": "ercPkBF8TY15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos el modelo con el conjunto de prueba\n",
        "results = model.evaluate(test_x, test_y)\n",
        "\n",
        "# Mostramos la p茅rdida y la precisi贸n final en el conjunto de prueba\n",
        "print('Final test set loss: {:4f}'.format(results[0]))\n",
        "print('Final test set accuracy: {:4f}'.format(results[1]))"
      ],
      "metadata": {
        "id": "e1rLUgTKPamq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Realizar una predicci贸n con un nuevo ejemplo**\n",
        "\n",
        "En esta celda, utilizamos el modelo entrenado para realizar una predicci贸n con un nuevo ejemplo. Luego, mostramos la clase predicha y el nombre correspondiente de la especie de Iris."
      ],
      "metadata": {
        "id": "YLExbJILThp4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aaca1y0YN6BC"
      },
      "outputs": [],
      "source": [
        "# Realizamos una predicci贸n con un nuevo ejemplo\n",
        "sample = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
        "\n",
        "# Obtenemos la predicci贸n del modelo y mostramos la clase predicha\n",
        "prediction = model.predict(sample)\n",
        "label = np.argmax(prediction)\n",
        "class_name = iris_data.target_names[label]\n",
        "print(f'Prediction: {label}')\n",
        "print(f'Class name: {class_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Guardar y cargar el modelo**\n",
        "\n",
        "Finalmente, guardamos el modelo entrenado en un archivo .keras y lo cargamos de nuevo para verificar que se pueda utilizar posteriormente. Luego, evaluamos el modelo cargado para asegurarnos de que se comporta igual que el original.\n",
        "\n",
        "> - **TensorFlow Docs:** [Save and load models - Save the entire model](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model)"
      ],
      "metadata": {
        "id": "UWRx-3cgTyz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardamos el modelo entrenado\n",
        "model.save('iris-model.keras')"
      ],
      "metadata": {
        "id": "KCaiRnH4QGgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este modelo puede ser descargado y cargado localmente."
      ],
      "metadata": {
        "id": "X7CRyQBJT9d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el modelo guardado\n",
        "iris_model = tf.keras.models.load_model('iris-model.keras')\n",
        "\n",
        "# Evaluamos el modelo cargado con los datos de prueba\n",
        "iris_model.evaluate(test_x, test_y)"
      ],
      "metadata": {
        "id": "WrPpxD3fQRUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "\n",
        "> Contenido creado por **Rodolfo Ferro**, 2024. <br>\n",
        "> Para cualquier retroalimentaci贸n, puedes contactarme a trav茅s del correo [ferro@cimat.mx](mailto:ferro@cimat.mx)."
      ],
      "metadata": {
        "id": "GCxE4OUCT75B"
      }
    }
  ]
}